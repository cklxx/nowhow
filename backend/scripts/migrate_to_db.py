#!/usr/bin/env python3
"""
æ•°æ®è¿ç§»è„šæœ¬ï¼šå°†æ–‡ä»¶å­˜å‚¨çš„æ•°æ®è¿ç§»åˆ° SQLite æ•°æ®åº“
"""

import sys
import os
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

from database.connection import init_database
from database.models import SourceModel, ArticleModel, WorkflowModel
from repositories.db_source_repository import DatabaseSourceRepository
from services.db_storage_service import DatabaseStorageService
from utils.source_manager import SourceManager

async def migrate_sources():
    """è¿ç§»ä¿¡æºé…ç½®"""
    print("ğŸ”„ å¼€å§‹è¿ç§»ä¿¡æºé…ç½®...")
    
    # åˆå§‹åŒ–æ—§çš„æ–‡ä»¶ç®¡ç†å™¨
    source_manager = SourceManager()
    
    # åˆå§‹åŒ–æ–°çš„æ•°æ®åº“å­˜å‚¨åº“
    db_repo = DatabaseSourceRepository()
    
    # è·å–æ‰€æœ‰ç°æœ‰ä¿¡æº
    file_sources = source_manager.get_all_sources(include_inactive=True)
    
    migrated_count = 0
    for source in file_sources:
        try:
            # æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²å­˜åœ¨
            existing = await db_repo.get_by_id(source.id)
            if existing:
                print(f"â­ï¸  ä¿¡æºå·²å­˜åœ¨ï¼Œè·³è¿‡: {source.name}")
                continue
            
            # åˆ›å»ºæ–°çš„ä¿¡æºè®°å½•
            source_data = source.model_dump()
            await db_repo.create(source_data)
            
            migrated_count += 1
            print(f"âœ… å·²è¿ç§»ä¿¡æº: {source.name}")
            
        except Exception as e:
            print(f"âŒ è¿ç§»ä¿¡æºå¤±è´¥ {source.name}: {e}")
    
    print(f"âœ… ä¿¡æºé…ç½®è¿ç§»å®Œæˆï¼Œå…±è¿ç§» {migrated_count} ä¸ªä¿¡æº")

async def migrate_articles():
    """è¿ç§»æ–‡ç« æ•°æ®"""
    print("ğŸ”„ å¼€å§‹è¿ç§»æ–‡ç« æ•°æ®...")
    
    # åˆå§‹åŒ–æ•°æ®åº“å­˜å‚¨æœåŠ¡
    db_storage = DatabaseStorageService()
    
    # æŸ¥æ‰¾æ‰€æœ‰æ–‡ç« æ–‡ä»¶
    data_dir = backend_dir / "data"
    articles_dir = data_dir / "articles"
    
    if not articles_dir.exists():
        print("ğŸ“ æ–‡ç« ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æ–‡ç« è¿ç§»")
        return
    
    migrated_count = 0
    for json_file in articles_dir.glob("articles_*.json"):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æå– workflow_id
            filename = json_file.stem
            parts = filename.split('_')
            if len(parts) >= 3:
                # æ ¼å¼: articles_timestamp_workflow_id
                workflow_id = parts[-1]
            else:
                workflow_id = f"migrated_{filename}"
            
            # å¤„ç†æ–‡ç« æ•°æ®
            articles = []
            if isinstance(data, dict):
                articles = data.get('articles', [])
            elif isinstance(data, list):
                articles = data
            
            if articles:
                await db_storage.save_generated_articles(workflow_id, articles)
                migrated_count += len(articles)
                print(f"âœ… å·²è¿ç§» {len(articles)} ç¯‡æ–‡ç«  (workflow: {workflow_id})")
            
        except Exception as e:
            print(f"âŒ è¿ç§»æ–‡ç« æ–‡ä»¶å¤±è´¥ {json_file}: {e}")
    
    print(f"âœ… æ–‡ç« æ•°æ®è¿ç§»å®Œæˆï¼Œå…±è¿ç§» {migrated_count} ç¯‡æ–‡ç« ")

async def migrate_workflows():
    """è¿ç§»å·¥ä½œæµæ•°æ®"""
    print("ğŸ”„ å¼€å§‹è¿ç§»å·¥ä½œæµæ•°æ®...")
    
    # åˆå§‹åŒ–æ•°æ®åº“å­˜å‚¨æœåŠ¡
    db_storage = DatabaseStorageService()
    
    # æŸ¥æ‰¾æ‰€æœ‰å·¥ä½œæµæ–‡ä»¶
    data_dir = backend_dir / "data"
    workflows_dir = data_dir / "workflows"
    
    if not workflows_dir.exists():
        print("ğŸ“ å·¥ä½œæµç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡å·¥ä½œæµè¿ç§»")
        return
    
    migrated_count = 0
    for json_file in workflows_dir.glob("*.json"):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            workflow_id = data.get('id', json_file.stem)
            
            # åˆ›å»ºå·¥ä½œæµçŠ¶æ€
            workflow_state = {
                'id': workflow_id,
                'name': data.get('name', f'Migrated Workflow {workflow_id}'),
                'description': data.get('description', ''),
                'config': data.get('config', {}),
                'status': data.get('status', 'completed'),
                'progress': data.get('progress', 100.0),
                'current_step': data.get('current_step', ''),
                'sources_count': data.get('sources_count', 0),
                'crawled_count': data.get('crawled_count', 0),
                'processed_count': data.get('processed_count', 0),
                'articles_generated': data.get('articles_generated', 0),
                'results': data.get('results', {}),
                'error_log': data.get('error_log', []),
                'execution_time': data.get('execution_time')
            }
            
            await db_storage.save_workflow_state(workflow_id, workflow_state)
            migrated_count += 1
            print(f"âœ… å·²è¿ç§»å·¥ä½œæµ: {workflow_id}")
            
        except Exception as e:
            print(f"âŒ è¿ç§»å·¥ä½œæµå¤±è´¥ {json_file}: {e}")
    
    print(f"âœ… å·¥ä½œæµæ•°æ®è¿ç§»å®Œæˆï¼Œå…±è¿ç§» {migrated_count} ä¸ªå·¥ä½œæµ")

def create_default_sources():
    """åˆ›å»ºé»˜è®¤çš„å†…ç½®ä¿¡æº"""
    print("ğŸ”„ åˆ›å»ºé»˜è®¤ä¿¡æºé…ç½®...")
    
    # ä½¿ç”¨æ–‡ä»¶ç®¡ç†å™¨çš„å†…ç½®ä¿¡æºåˆå§‹åŒ–åŠŸèƒ½
    source_manager = SourceManager()
    source_manager._init_builtin_sources()
    
    print("âœ… é»˜è®¤ä¿¡æºé…ç½®åˆ›å»ºå®Œæˆ")

async def main():
    """ä¸»è¿ç§»æµç¨‹"""
    print("ğŸš€ å¼€å§‹æ•°æ®åº“è¿ç§»...")
    print(f"ğŸ“ åç«¯ç›®å½•: {backend_dir}")
    
    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        print("ğŸ”§ åˆå§‹åŒ–æ•°æ®åº“...")
        db_manager = init_database()
        print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        
        # æ‰§è¡Œè¿ç§»
        await migrate_sources()
        await migrate_articles()
        await migrate_workflows()
        
        print("\nğŸ‰ æ‰€æœ‰æ•°æ®è¿ç§»å®Œæˆ!")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š è¿ç§»ç»Ÿè®¡:")
        
        # ç»Ÿè®¡ä¿¡æº
        db_repo = DatabaseSourceRepository()
        sources = await db_repo.get_all()
        print(f"   ä¿¡æºæ€»æ•°: {len(sources)}")
        
        # ç»Ÿè®¡æ–‡ç« 
        db_storage = DatabaseStorageService()
        articles = await db_storage.load_generated_articles()
        print(f"   æ–‡ç« æ€»æ•°: {len(articles)}")
        
        # ç»Ÿè®¡å·¥ä½œæµ
        session = db_manager.get_sync_session()
        try:
            workflow_count = session.query(WorkflowModel).count()
            print(f"   å·¥ä½œæµæ€»æ•°: {workflow_count}")
        finally:
            session.close()
        
    except Exception as e:
        print(f"âŒ è¿ç§»å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())