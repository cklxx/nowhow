#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿¡æºè¿ç§»è„šæœ¬ï¼šå°† YAML é…ç½®çš„ä¿¡æºè¿ç§»åˆ° SQLite æ•°æ®åº“
"""

import sys
import os
import yaml
import asyncio
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

from database.connection import init_database
from repositories.db_source_repository import DatabaseSourceRepository
from models.source_config import SourceConfig, SourceType, ContentType


class SourceMigrator:
    """ä¿¡æºè¿ç§»å™¨"""
    
    def __init__(self):
        self.db_repo = DatabaseSourceRepository()
        self.migrated_count = 0
        self.skipped_count = 0
        self.error_count = 0
        
    def load_yaml_sources(self, yaml_file: Path) -> List[Dict[str, Any]]:
        """åŠ è½½ YAML é…ç½®æ–‡ä»¶ä¸­çš„ä¿¡æº"""
        print(f"ğŸ“ è¯»å–é…ç½®æ–‡ä»¶: {yaml_file}")
        
        try:
            with open(yaml_file, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
            
            sources = []
            
            # å¤„ç† RSS ä¿¡æº
            if 'sources' in data and 'rss_feeds' in data['sources']:
                for source in data['sources']['rss_feeds']:
                    source_data = self._convert_yaml_source(source, 'rss')
                    if source_data:
                        sources.append(source_data)
            
            # å¤„ç†ç½‘ç«™ä¿¡æº
            if 'sources' in data and 'websites' in data['sources']:
                for source in data['sources']['websites']:
                    source_data = self._convert_yaml_source(source, 'website')
                    if source_data:
                        sources.append(source_data)
            
            # å¤„ç†å¤‡ç”¨ä¿¡æº
            if 'backup_sources' in data and 'rss_feeds' in data['backup_sources']:
                for source in data['backup_sources']['rss_feeds']:
                    source_data = self._convert_yaml_source(source, 'rss', priority='low')
                    if source_data:
                        sources.append(source_data)
            
            print(f"âœ… æˆåŠŸè§£æ {len(sources)} ä¸ªä¿¡æº")
            return sources
            
        except Exception as e:
            print(f"âŒ è¯»å– YAML æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def _convert_yaml_source(self, yaml_source: Dict[str, Any], source_type: str, priority: str = None) -> Optional[Dict[str, Any]]:
        """å°† YAML ä¿¡æºé…ç½®è½¬æ¢ä¸ºæ•°æ®åº“æ ¼å¼"""
        try:
            # æ˜ å°„ä¿¡æºç±»å‹
            type_mapping = {
                'rss': SourceType.RSS,
                'website': SourceType.WEBSITE,
                'api': SourceType.API
            }
            
            # æ˜ å°„å†…å®¹ç±»å‹
            category = yaml_source.get('category', 'news')
            content_type_mapping = {
                'research': ContentType.RESEARCH,
                'news': ContentType.NEWS,
                'blog': ContentType.BLOG,
                'analysis': ContentType.ARTICLE,
                'education': ContentType.ARTICLE,
                'industry': ContentType.NEWS,
                'cloud': ContentType.ARTICLE,
                'agents': ContentType.RESEARCH,
                'documentation': ContentType.ARTICLE
            }
            
            # è®¾ç½®ä¼˜å…ˆçº§
            if not priority:
                priority = yaml_source.get('priority', 'medium')
            
            # æŠ“å–é…ç½®
            crawl_config = {
                'timeout': 30,
                'max_retries': 3,
                'priority': priority,
                'requires_parsing': yaml_source.get('requires_parsing', False),
                'verified': yaml_source.get('verified', False),
                'last_checked': yaml_source.get('last_checked', datetime.now().strftime('%Y-%m-%d'))
            }
            
            # è¯­è¨€é…ç½®
            language = yaml_source.get('language', 'en')
            if language == 'zh':
                crawl_config['language'] = 'chinese'
            
            return {
                'id': yaml_source['id'],
                'name': yaml_source['name'],
                'url': yaml_source['url'],
                'type': type_mapping.get(source_type, SourceType.WEBSITE),
                'content_type': content_type_mapping.get(category, ContentType.ARTICLE),
                'description': yaml_source.get('description', ''),
                'crawl_config': crawl_config,
                'auth_config': {},
                'content_selectors': {},
                'is_active': True,
                'is_built_in': True,  # æ¥è‡ªé…ç½®æ–‡ä»¶çš„éƒ½æ ‡è®°ä¸ºå†…ç½®
                'created_by': 'system',
                'quality_score': self._get_quality_score(priority),
                'relevance_score': self._get_relevance_score(category)
            }
            
        except Exception as e:
            print(f"âŒ è½¬æ¢ä¿¡æºé…ç½®å¤±è´¥ {yaml_source.get('name', 'Unknown')}: {e}")
            return None
    
    def _get_quality_score(self, priority: str) -> float:
        """æ ¹æ®ä¼˜å…ˆçº§è·å–è´¨é‡åˆ†æ•°"""
        score_mapping = {
            'high': 0.9,
            'medium': 0.7,
            'low': 0.5
        }
        return score_mapping.get(priority, 0.7)
    
    def _get_relevance_score(self, category: str) -> float:
        """æ ¹æ®åˆ†ç±»è·å–ç›¸å…³æ€§åˆ†æ•°"""
        score_mapping = {
            'research': 0.95,
            'agents': 0.95,
            'news': 0.8,
            'analysis': 0.85,
            'education': 0.8,
            'industry': 0.75,
            'cloud': 0.7
        }
        return score_mapping.get(category, 0.75)
    
    async def migrate_source(self, source_data: Dict[str, Any]) -> bool:
        """è¿ç§»å•ä¸ªä¿¡æº"""
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = await self.db_repo.get_by_id(source_data['id'])
            if existing:
                print(f"â­ï¸  ä¿¡æºå·²å­˜åœ¨ï¼Œè·³è¿‡: {source_data['name']}")
                self.skipped_count += 1
                return True
            
            # åˆ›å»ºæ–°ä¿¡æº
            await self.db_repo.create(source_data)
            print(f"âœ… å·²è¿ç§»ä¿¡æº: {source_data['name']}")
            self.migrated_count += 1
            return True
            
        except Exception as e:
            print(f"âŒ è¿ç§»ä¿¡æºå¤±è´¥ {source_data['name']}: {e}")
            self.error_count += 1
            return False
    
    async def migrate_all_sources(self) -> None:
        """è¿ç§»æ‰€æœ‰ä¿¡æº"""
        print("ğŸš€ å¼€å§‹ä¿¡æºè¿ç§»...")
        
        # æŸ¥æ‰¾æ‰€æœ‰ YAML é…ç½®æ–‡ä»¶
        yaml_files = [
            backend_dir / "sources_premium.yml",
            backend_dir / "sources.yml",
            backend_dir / "data" / "sources.yml"
        ]
        
        all_sources = []
        for yaml_file in yaml_files:
            if yaml_file.exists():
                sources = self.load_yaml_sources(yaml_file)
                all_sources.extend(sources)
        
        if not all_sources:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯è¿ç§»çš„ä¿¡æºé…ç½®")
            return
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(all_sources)} ä¸ªä¿¡æºé…ç½®ï¼Œå¼€å§‹è¿ç§»...")
        
        # é€ä¸ªè¿ç§»ä¿¡æº
        for source_data in all_sources:
            await self.migrate_source(source_data)
        
        # æ˜¾ç¤ºè¿ç§»ç»“æœ
        print(f"\nğŸ‰ ä¿¡æºè¿ç§»å®Œæˆ!")
        print(f"   âœ… æˆåŠŸè¿ç§»: {self.migrated_count}")
        print(f"   â­ï¸  è·³è¿‡é‡å¤: {self.skipped_count}")
        print(f"   âŒ è¿ç§»å¤±è´¥: {self.error_count}")
        print(f"   ğŸ“Š æ€»è®¡å¤„ç†: {len(all_sources)}")
    
    async def display_statistics(self) -> None:
        """æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
        
        try:
            stats = await self.db_repo.get_statistics()
            print(f"   æ€»ä¿¡æºæ•°: {stats['total_sources']}")
            print(f"   æ´»è·ƒä¿¡æº: {stats['active_sources']}")
            print(f"   å†…ç½®ä¿¡æº: {stats['builtin_sources']}")
            print(f"   ç”¨æˆ·ä¿¡æº: {stats['user_sources']}")
            
            print(f"\n   æŒ‰ç±»å‹åˆ†å¸ƒ:")
            for source_type, count in stats['by_type'].items():
                print(f"     {source_type}: {count}")
            
            print(f"\n   æŒ‰å†…å®¹ç±»å‹åˆ†å¸ƒ:")
            for content_type, count in stats['by_content_type'].items():
                print(f"     {content_type}: {count}")
                
        except Exception as e:
            print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ—ƒï¸  ä¿¡æºæ•°æ®åº“è¿ç§»å·¥å…·")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        print("ğŸ”§ åˆå§‹åŒ–æ•°æ®åº“...")
        init_database()
        print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        
        # åˆ›å»ºè¿ç§»å™¨
        migrator = SourceMigrator()
        
        # æ‰§è¡Œè¿ç§»
        await migrator.migrate_all_sources()
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        await migrator.display_statistics()
        
        print("\nğŸŠ è¿ç§»ä»»åŠ¡å…¨éƒ¨å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())