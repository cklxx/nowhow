{
  "id": "a7340d4f-1713-4f98-ba99-4f2cecdc6145",
  "title": "Virtual Personas for Language Models via an Anthology of Backstories",
  "content": "We introduce Anthology, a method for conditioning LLMs to representative, consistent, and diverse virtual personas by generating and utilizing naturalistic backstories with rich details of individual values and experience.\n\nWhat does it mean for large language models (LLMs) to be trained on massive text corpora, collectively produced by millions and billions of distinctive human authors?\nIn \u201cLanguage Models as Agent Models\u201d, compelling evidence suggests that recent language models could be considered models of agents: provided with a textual context, LLMs are capable of generating conditional text that represents the characteristics of an agent likely to have produced that context. This suggests that, with appropriate conditioning, LLMs could be guided to approximate the responses of a particular human voice, rather than the mixture of voices that otherwise emerges. If realized, this capability of LLMs would have significant implications for user research and social sciences\u2014conditioned language models as virtual personas of human subjects could serve as cost-effective pilot studies and supporting best practices in human studies, e.g. the Belmont principles of justice and beneficence.\nIn this work, we introduce Anthology, an approach for steering LLMs to representative, consistent, and diverse virtual personas by providing richly detailed life narratives of individuals as conditioning context to models.\n\nIn doing so, we also present methods to generate backstories from LLMs themselves as a means to efficiently produce massive sets covering a wide range of human demographics.\nBy grounding language models in naturalistic backstories, Anthology allows LLMs to simulate individual human samples with increased fidelity, measured in terms of matching the distributions and consistencies of human responses.\nOur Approach: Anthology\nConditioning Language Model Generation with Individual Life Narratives\nA significant limitation of earlier methods in steering LLMs to virtual personas has been the inability to reliably approximate individual human samples. Prior approaches prompt LLMs with broad demographic information, e.g., \u201cI am a 25-year-old from California. My highest level of education is less than high school,\u201d which are essentially bodies of text generated from a tuple of demographic variables. \nWith these methods, we are only able to approximate human samples at a population level, not at the individual level, which results in:\n\nResponses prone to LLMs defaulting to stereotypical and/or prototypical portrayals, as they are only conditioned on demographic variables (e.g., race and gender)\nInability to provide important metrics of interest such as covariance and statistical significance, as individual responses are required for such compuatations\n\nAnthology enables the approximation of individual subjects by conditioning with richly detailed backstories. Through these backstories, the model captures implicit and explicit markers of personal identity, including demographic traits and spontaneous references to cultural, socioeconomic backgrounds, and life philosophies. Our approach involves generating a vast set of backstories representing a wide range of demographic attributes via language models queried with unrestricted, open-ended prompts such as, \u201cTell me about yourself.\u201d We then match virtual personas conditioned by each backstory to real-world survey samples.\nResults: Closer Approximation of Public Opinion Polls\nFor evaluation, we compare the effectiveness of different methods for conditioning virtual personas in the context of approximating three Pew Research Center ATP surveys: Waves 34, 92, and 99.\n\n\n\nResults on approximating human responses for Pew Research Center ATP surveys. Boldface and underlined results indicate values closest and the second closest to those of humans, respectively.\n\nAs measures of success in approximating human samples with virtual personas, we consider the following metrics:\n\nAverage Wasserstein distance (WD) between response distributions as a measure of representativeness\nFrobenius norm (Fro.) between correlation matrices as a measure of consistency\nCronbach\u2019s alpha as an additional measure of internal consistency\n\nPrior to analyzing virtual subjects, we estimate the lower bounds of each evaluation metric by repeatedly dividing the human population into two equal-sized groups at random and calculating these metrics between the subgroups. \nWe take averaged values from 100 iterations to represent the lower-bound estimates.\nWe consistently observe that Anthology outperforms other conditioning methods with respect to all metrics, for both the Llama-3-70B and the Mixtral-8x22B. \nWhen comparing two matching methods, the greedy matching method tends to show better performance on the average Wasserstein distance across all Waves. We attribute differences in matching methods to the one-to-one correspondence condition of maximum weight matching and the limited number of virtual users available. Specifically, the weights assigned to matched virtual subjects in maximum weight matching are inevitably lower than those in greedy matching, as the latter relaxes the constraints on one-to-one correspondence. This discrepancy can result in a lower demographic similarity between matched human and virtual users compared to the counterpart from greedy matching. These results suggest that the richness of the generated backstories in our approach elicits more nuanced responses compared to baselines.\nFinal Thoughts\nAnthology marks a promising new direction in conditioning virtual personas in LLMs that could potentially reshape how we conduct user research, public opinion surveys, and other social science applications by offering a scalable, and at times, ethical alternative to traditional human surveys.\nHowever, the use of Anthology, as in any other application of language models in the social sciences, also brings several considerations to the forefront: although the generated backstories help create more representative personas, there remains a risk of perpetuating biases or infringing on privacy, so results should be used and interpreted with caution.\nIn terms of future steps, we envision our approach benefiting from a more expansive and diverse set of backstories, each representing a consistent life narrative of individuals.\nAdditionally, a valuable extension of the work would be to consider free-form response generation, enabling more natural and nuanced persona simulations beyond structured survey formats such as multiple-choice. \nFinally, an exciting next dimension in applying LLMs in behavioral studies would involve simulating longer-term effects, allowing virtual personas to model and retrospectively examine changes over time.\nAll of these directions present multitudes of technical challenges; please let us know if you are interested in collaborating or want to discuss our work further!\nLearn more about our work:  link to full paper \n@article{moon2024virtual,\n  title={Virtual personas for language models via an anthology of backstories},\n  author={Moon, Suhong and Abdulhai, Marwa and Kang, Minwoo and Suh, Joseph and Soedarmadji, Widyadewi and Behar, Eran Kohen and Chan, David M},\n  journal={arXiv preprint arXiv:2407.06576},\n  year={2024}\n}",
  "url": "http://bair.berkeley.edu/blog/2024/11/12/virutal-persona-llm/",
  "source_id": "038d31d6-2e17-4a9c-b561-b53734aa9ff8",
  "category": "research",
  "author": "",
  "published_at": null,
  "created_at": "2025-07-01T16:55:18.572963",
  "quality_score": 0.9999999999999999,
  "metadata": {
    "workflow_id": "15333d42-b6a3-4b3f-8c33-91b70037ccf5",
    "extraction_method": "rss",
    "original_item": {
      "title": "Virtual Personas for Language Models via an Anthology of Backstories",
      "content": "We introduce Anthology, a method for conditioning LLMs to representative, consistent, and diverse virtual personas by generating and utilizing naturalistic backstories with rich details of individual values and experience.\n\nWhat does it mean for large language models (LLMs) to be trained on massive text corpora, collectively produced by millions and billions of distinctive human authors?\nIn \u201cLanguage Models as Agent Models\u201d, compelling evidence suggests that recent language models could be considered models of agents: provided with a textual context, LLMs are capable of generating conditional text that represents the characteristics of an agent likely to have produced that context. This suggests that, with appropriate conditioning, LLMs could be guided to approximate the responses of a particular human voice, rather than the mixture of voices that otherwise emerges. If realized, this capability of LLMs would have significant implications for user research and social sciences\u2014conditioned language models as virtual personas of human subjects could serve as cost-effective pilot studies and supporting best practices in human studies, e.g. the Belmont principles of justice and beneficence.\nIn this work, we introduce Anthology, an approach for steering LLMs to representative, consistent, and diverse virtual personas by providing richly detailed life narratives of individuals as conditioning context to models.\n\nIn doing so, we also present methods to generate backstories from LLMs themselves as a means to efficiently produce massive sets covering a wide range of human demographics.\nBy grounding language models in naturalistic backstories, Anthology allows LLMs to simulate individual human samples with increased fidelity, measured in terms of matching the distributions and consistencies of human responses.\nOur Approach: Anthology\nConditioning Language Model Generation with Individual Life Narratives\nA significant limitation of earlier methods in steering LLMs to virtual personas has been the inability to reliably approximate individual human samples. Prior approaches prompt LLMs with broad demographic information, e.g., \u201cI am a 25-year-old from California. My highest level of education is less than high school,\u201d which are essentially bodies of text generated from a tuple of demographic variables. \nWith these methods, we are only able to approximate human samples at a population level, not at the individual level, which results in:\n\nResponses prone to LLMs defaulting to stereotypical and/or prototypical portrayals, as they are only conditioned on demographic variables (e.g., race and gender)\nInability to provide important metrics of interest such as covariance and statistical significance, as individual responses are required for such compuatations\n\nAnthology enables the approximation of individual subjects by conditioning with richly detailed backstories. Through these backstories, the model captures implicit and explicit markers of personal identity, including demographic traits and spontaneous references to cultural, socioeconomic backgrounds, and life philosophies. Our approach involves generating a vast set of backstories representing a wide range of demographic attributes via language models queried with unrestricted, open-ended prompts such as, \u201cTell me about yourself.\u201d We then match virtual personas conditioned by each backstory to real-world survey samples.\nResults: Closer Approximation of Public Opinion Polls\nFor evaluation, we compare the effectiveness of different methods for conditioning virtual personas in the context of approximating three Pew Research Center ATP surveys: Waves 34, 92, and 99.\n\n\n\nResults on approximating human responses for Pew Research Center ATP surveys. Boldface and underlined results indicate values closest and the second closest to those of humans, respectively.\n\nAs measures of success in approximating human samples with virtual personas, we consider the following metrics:\n\nAverage Wasserstein distance (WD) between response distributions as a measure of representativeness\nFrobenius norm (Fro.) between correlation matrices as a measure of consistency\nCronbach\u2019s alpha as an additional measure of internal consistency\n\nPrior to analyzing virtual subjects, we estimate the lower bounds of each evaluation metric by repeatedly dividing the human population into two equal-sized groups at random and calculating these metrics between the subgroups. \nWe take averaged values from 100 iterations to represent the lower-bound estimates.\nWe consistently observe that Anthology outperforms other conditioning methods with respect to all metrics, for both the Llama-3-70B and the Mixtral-8x22B. \nWhen comparing two matching methods, the greedy matching method tends to show better performance on the average Wasserstein distance across all Waves. We attribute differences in matching methods to the one-to-one correspondence condition of maximum weight matching and the limited number of virtual users available. Specifically, the weights assigned to matched virtual subjects in maximum weight matching are inevitably lower than those in greedy matching, as the latter relaxes the constraints on one-to-one correspondence. This discrepancy can result in a lower demographic similarity between matched human and virtual users compared to the counterpart from greedy matching. These results suggest that the richness of the generated backstories in our approach elicits more nuanced responses compared to baselines.\nFinal Thoughts\nAnthology marks a promising new direction in conditioning virtual personas in LLMs that could potentially reshape how we conduct user research, public opinion surveys, and other social science applications by offering a scalable, and at times, ethical alternative to traditional human surveys.\nHowever, the use of Anthology, as in any other application of language models in the social sciences, also brings several considerations to the forefront: although the generated backstories help create more representative personas, there remains a risk of perpetuating biases or infringing on privacy, so results should be used and interpreted with caution.\nIn terms of future steps, we envision our approach benefiting from a more expansive and diverse set of backstories, each representing a consistent life narrative of individuals.\nAdditionally, a valuable extension of the work would be to consider free-form response generation, enabling more natural and nuanced persona simulations beyond structured survey formats such as multiple-choice. \nFinally, an exciting next dimension in applying LLMs in behavioral studies would involve simulating longer-term effects, allowing virtual personas to model and retrospectively examine changes over time.\nAll of these directions present multitudes of technical challenges; please let us know if you are interested in collaborating or want to discuss our work further!\nLearn more about our work:  link to full paper \n@article{moon2024virtual,\n  title={Virtual personas for language models via an anthology of backstories},\n  author={Moon, Suhong and Abdulhai, Marwa and Kang, Minwoo and Suh, Joseph and Soedarmadji, Widyadewi and Behar, Eran Kohen and Chan, David M},\n  journal={arXiv preprint arXiv:2407.06576},\n  year={2024}\n}",
      "url": "http://bair.berkeley.edu/blog/2024/11/12/virutal-persona-llm/",
      "author": "",
      "published": "Tue, 12 Nov 2024 01:00:00 -0800",
      "category": "research",
      "source_id": "038d31d6-2e17-4a9c-b561-b53734aa9ff8",
      "extraction_method": "rss"
    }
  }
}